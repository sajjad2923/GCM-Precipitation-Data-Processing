{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the input and output directories\n",
    "input_directory = r'D:\\Thesis\\Thesis Papers\\GCM SWAT Integration\\Models Dataset\\Pr\\SSP4.5'\n",
    "output_directory = r'D:\\Thesis\\Thesis Papers\\GCM SWAT Integration\\Models Dataset\\Pr\\SSP4.5'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get the list of NetCDF files in the input directory\n",
    "file_list = [f for f in os.listdir(input_directory) if f.endswith('.nc')]\n",
    "\n",
    "# Specify the list of latitude and longitude pairs\n",
    "coordinates_list = [(25.62, 40.31, 'A1'),\n",
    "                    (24.38, 40.31, 'A2'),\n",
    "                    (24.38, 42.21, 'A3'),\n",
    "                    (23.13, 42.19, 'A4'),\n",
    "                    (23.11, 40.79, 'A5'),\n",
    "                    (23.11, 39.38, 'A6')]\n",
    "\n",
    "# Create a dictionary to store time series for each coordinate\n",
    "coordinate_timeseries = {coord: pd.DataFrame() for coord in coordinates_list}\n",
    "\n",
    "# Loop through each file\n",
    "for file_name in file_list:\n",
    "    # Construct the file path\n",
    "    file_path = os.path.join(input_directory, file_name)\n",
    "\n",
    "    # Read the NetCDF file using xarray\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    # Access the precipitation variable\n",
    "    pr_variable = ds['pr']\n",
    "\n",
    "    # Create a new folder for the file's output\n",
    "    file_output_directory = os.path.join(output_directory, file_name[:-3])\n",
    "    os.makedirs(file_output_directory, exist_ok=True)\n",
    "\n",
    "    # Filter the time series from 01/01/2026 to 31/12/2100\n",
    "    pr_variable_filtered = pr_variable.sel(time=slice('2026-01-01', '2100-12-31'))\n",
    "\n",
    "    # Create an Excel writer\n",
    "    excel_file_path = os.path.join(file_output_directory, f'{file_name[:-3]}.xlsx')\n",
    "    with pd.ExcelWriter(excel_file_path) as writer:\n",
    "\n",
    "        # Loop through coordinates\n",
    "        for lat, lon, station_name in coordinates_list:\n",
    "            # Find the nearest indices in the lat and lon dimensions\n",
    "            lat_index = np.abs(pr_variable_filtered.lat - lat).argmin()\n",
    "            lon_index = np.abs(pr_variable_filtered.lon - lon).argmin()\n",
    "\n",
    "            # Extract the precipitation values at the specified indices\n",
    "            pr_at_location = pr_variable_filtered[:, lat_index, lon_index]\n",
    "\n",
    "            # Convert the units to mm/day\n",
    "            pr_at_location_mm_per_day = pr_at_location * 86400\n",
    "\n",
    "            # Add the date at the beginning of each text file\n",
    "            pr_dataframe = pr_at_location_mm_per_day.to_dataframe()\n",
    "            pr_dataframe.index = pd.date_range(start='2026-01-01', periods=len(pr_dataframe), freq='D')\n",
    "\n",
    "            # Save the 'pr' variable values to a text file without the '#' in the header\n",
    "            text_file_path = os.path.join(file_output_directory, f'{station_name}.txt')\n",
    "            np.savetxt(text_file_path, pr_dataframe['pr'].values, fmt='%.6f', header='20260101', comments='')\n",
    "\n",
    "            # Save the 'pr' variable values to an Excel sheet with the station name as the sheet name\n",
    "            pr_dataframe.to_excel(writer, sheet_name=f'station_{station_name}', index=False, header=None)\n",
    "\n",
    "            # Add the time series to the coordinate_timeseries dictionary\n",
    "            coordinate_timeseries[(lat, lon, station_name)][file_name[:-3]] = pr_dataframe['pr']\n",
    "\n",
    "        # Create a new dataframe for average values\n",
    "        average_dataframe = pd.DataFrame()\n",
    "\n",
    "        # Loop through coordinates again to calculate the average\n",
    "        for lat, lon, _ in coordinates_list:\n",
    "            # Find the nearest indices in the lat and lon dimensions\n",
    "            lat_index = np.abs(pr_variable_filtered.lat - lat).argmin()\n",
    "            lon_index = np.abs(pr_variable_filtered.lon - lon).argmin()\n",
    "\n",
    "            # Extract the precipitation values at the specified indices\n",
    "            pr_at_location = pr_variable_filtered[:, lat_index, lon_index]\n",
    "\n",
    "            # Convert the units to mm/day\n",
    "            pr_at_location_mm_per_day = pr_at_location * 86400\n",
    "\n",
    "            # Add the precipitation values to the average dataframe\n",
    "            average_dataframe[f'Lat={lat}, Lon={lon}'] = pr_at_location_mm_per_day\n",
    "\n",
    "        # Calculate the average of all time series\n",
    "        average_dataframe['Average'] = average_dataframe.mean(axis=1)\n",
    "\n",
    "        # Set the index as date range\n",
    "        average_dataframe.index = pd.date_range(start='2026-01-01', periods=len(average_dataframe), freq='D')\n",
    "\n",
    "        # Save the average values to a separate sheet in the Excel file\n",
    "        average_dataframe.to_excel(writer, sheet_name='Average', index=True)\n",
    "\n",
    "    # Close the dataset when you are done with the current file\n",
    "    ds.close()\n",
    "\n",
    "# Create a directory for the coordinate time series text files\n",
    "coordinate_timeseries_txt_directory = os.path.join(output_directory, 'coordinate_timeseries_txt')\n",
    "os.makedirs(coordinate_timeseries_txt_directory, exist_ok=True)\n",
    "\n",
    "# Create an Excel file for the coordinate time series\n",
    "coordinate_timeseries_file_path = os.path.join(output_directory, 'coordinate_timeseries.xlsx')\n",
    "with pd.ExcelWriter(coordinate_timeseries_file_path) as writer:\n",
    "    for coord, timeseries_df in coordinate_timeseries.items():\n",
    "        # Add the average column\n",
    "        timeseries_df['Average'] = timeseries_df.mean(axis=1)\n",
    "\n",
    "        # Save the time series to a sheet in the Excel file\n",
    "        sheet_name = f\"{coord[2]}\"\n",
    "        timeseries_df.to_excel(writer, sheet_name=sheet_name)\n",
    "\n",
    "        # Save the Average time series to a text file\n",
    "        average_timeseries = timeseries_df['Average']\n",
    "        text_file_path = os.path.join(coordinate_timeseries_txt_directory, f'{coord[2]}.txt')\n",
    "        np.savetxt(text_file_path, average_timeseries.values, fmt='%.6f', header='20260101', comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the input and output directories\n",
    "input_directory = r'D:\\GCM\\Dataset\\GFDL'\n",
    "output_directory = r'D:\\GCM\\Dataset\\GFDL\\output'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get the list of NetCDF files in the input directory\n",
    "file_list = [f for f in os.listdir(input_directory) if f.endswith('.nc')]\n",
    "\n",
    "# Specify the list of latitude and longitude pairs\n",
    "coordinates_list = [(25.62, 40.31, 'A1'),\n",
    "                    (24.38, 40.31, 'A2'),\n",
    "                    (24.38, 42.21, 'A3'),\n",
    "                    (23.13, 42.19, 'A4'),\n",
    "                    (23.11, 40.79, 'A5'),\n",
    "                    (23.11, 39.38, 'A6')]\n",
    "\n",
    "# Create a dictionary to store time series for each coordinate\n",
    "coordinate_timeseries = {coord: pd.DataFrame() for coord in coordinates_list}\n",
    "\n",
    "# Loop through each file\n",
    "for file_name in file_list:\n",
    "    # Construct the file path\n",
    "    file_path = os.path.join(input_directory, file_name)\n",
    "\n",
    "    # Read the NetCDF file using xarray\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    # Access the precipitation variable\n",
    "    pr_variable = ds['pr']\n",
    "\n",
    "    # Create a new folder for the file's output\n",
    "    file_output_directory = os.path.join(output_directory, file_name[:-3])\n",
    "    os.makedirs(file_output_directory, exist_ok=True)\n",
    "\n",
    "    # Filter the time series from 01/01/1979 to 31/12/2010\n",
    "    pr_variable_filtered = pr_variable.sel(time=slice('1979-01-01', '2005-12-31'))\n",
    "\n",
    "    # Create an Excel writer\n",
    "    excel_file_path = os.path.join(file_output_directory, f'{file_name[:-3]}.xlsx')\n",
    "    with pd.ExcelWriter(excel_file_path) as writer:\n",
    "\n",
    "        # Loop through coordinates\n",
    "        for lat, lon, station_name in coordinates_list:\n",
    "            # Find the nearest indices in the lat and lon dimensions\n",
    "            lat_index = np.abs(pr_variable_filtered.lat - lat).argmin()\n",
    "            lon_index = np.abs(pr_variable_filtered.lon - lon).argmin()\n",
    "\n",
    "            # Extract the precipitation values at the specified indices\n",
    "            pr_at_location = pr_variable_filtered[:, lat_index, lon_index]\n",
    "\n",
    "            # Convert the units to mm/day\n",
    "            pr_at_location_mm_per_day = pr_at_location * 86400\n",
    "\n",
    "            # Add the date at the beginning of each text file\n",
    "            pr_dataframe = pr_at_location_mm_per_day.to_dataframe()\n",
    "            pr_dataframe.index = pd.date_range(start='1979-01-01', periods=len(pr_dataframe), freq='D')\n",
    "\n",
    "            # Save the 'pr' variable values to a text file without the '#' in the header\n",
    "            text_file_path = os.path.join(file_output_directory, f'{station_name}.txt')\n",
    "            np.savetxt(text_file_path, pr_dataframe['pr'].values, fmt='%.6f', header='19790101', comments='')\n",
    "\n",
    "            # Save the 'pr' variable values to an Excel sheet with the station name as the sheet name\n",
    "            pr_dataframe.to_excel(writer, sheet_name=f'station_{station_name}', index=False, header=None)\n",
    "\n",
    "            # Add the time series to the coordinate_timeseries dictionary\n",
    "            coordinate_timeseries[(lat, lon, station_name)][file_name[:-3]] = pr_dataframe['pr']\n",
    "\n",
    "        # Create a new dataframe for average values\n",
    "        average_dataframe = pd.DataFrame()\n",
    "\n",
    "        # Loop through coordinates again to calculate the average\n",
    "        for lat, lon, _ in coordinates_list:\n",
    "            # Find the nearest indices in the lat and lon dimensions\n",
    "            lat_index = np.abs(pr_variable_filtered.lat - lat).argmin()\n",
    "            lon_index = np.abs(pr_variable_filtered.lon - lon).argmin()\n",
    "\n",
    "            # Extract the precipitation values at the specified indices\n",
    "            pr_at_location = pr_variable_filtered[:, lat_index, lon_index]\n",
    "\n",
    "            # Convert the units to mm/day\n",
    "            pr_at_location_mm_per_day = pr_at_location * 86400\n",
    "\n",
    "            # Add the precipitation values to the average dataframe\n",
    "            average_dataframe[f'Lat={lat}, Lon={lon}'] = pr_at_location_mm_per_day\n",
    "\n",
    "        # Calculate the average of all time series\n",
    "        average_dataframe['Average'] = average_dataframe.mean(axis=1)\n",
    "\n",
    "        # Set the index as date range\n",
    "        average_dataframe.index = pd.date_range(start='1979-01-01', periods=len(average_dataframe), freq='D')\n",
    "\n",
    "        # Save the average values to a separate sheet in the Excel file\n",
    "        average_dataframe.to_excel(writer, sheet_name='Average', index=True)\n",
    "\n",
    "    # Close the dataset when you are done with the current file\n",
    "    ds.close()\n",
    "\n",
    "# Create a directory for the coordinate time series text files\n",
    "coordinate_timeseries_txt_directory = os.path.join(output_directory, 'coordinate_timeseries_txt')\n",
    "os.makedirs(coordinate_timeseries_txt_directory, exist_ok=True)\n",
    "\n",
    "# Create an Excel file for the coordinate time series\n",
    "coordinate_timeseries_file_path = os.path.join(output_directory, 'coordinate_timeseries.xlsx')\n",
    "with pd.ExcelWriter(coordinate_timeseries_file_path) as writer:\n",
    "    for coord, timeseries_df in coordinate_timeseries.items():\n",
    "        # Add the average column\n",
    "        timeseries_df['Average'] = timeseries_df.mean(axis=1)\n",
    "\n",
    "        # Save the time series to a sheet in the Excel file\n",
    "        sheet_name = f\"{coord[2]}\"\n",
    "        timeseries_df.to_excel(writer, sheet_name=sheet_name)\n",
    "\n",
    "        # Save the Average time series to a text file\n",
    "        average_timeseries = timeseries_df['Average']\n",
    "        text_file_path = os.path.join(coordinate_timeseries_txt_directory, f'{coord[2]}.txt')\n",
    "        np.savetxt(text_file_path, average_timeseries.values, fmt='%.6f', header='19790101', comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
